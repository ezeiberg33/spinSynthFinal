{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Using cycleGAN model to harmonize the images. The model is making the scans from Guys look more like the scans from HH."
      ],
      "metadata": {
        "id": "Els25yK_QTCR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSKATJ1ynMDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57bb57dc-55c2-4952-e710-9840987a2d00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Collecting monai\n",
            "  Downloading monai-1.5.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.12/dist-packages (5.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Collecting SimpleITK\n",
            "  Downloading simpleitk-2.5.3-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: torch>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from monai) (2.9.0+cu126)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from nibabel) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.12/dist-packages (from nibabel) (4.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.1->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.1->monai) (3.0.3)\n",
            "Downloading monai-1.5.1-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading simpleitk-2.5.3-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (52.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SimpleITK, monai\n",
            "Successfully installed SimpleITK-2.5.3 monai-1.5.1\n",
            "Collecting neuroHarmonize\n",
            "  Downloading neuroHarmonize-2.4.5-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nilearn\n",
            "  Downloading nilearn-0.12.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from nilearn) (1.5.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from nilearn) (6.0.2)\n",
            "Requirement already satisfied: nibabel>=5.2.0 in /usr/local/lib/python3.12/dist-packages (from nilearn) (5.3.3)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.12/dist-packages (from nilearn) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from nilearn) (25.0)\n",
            "Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from nilearn) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.12/dist-packages (from nilearn) (2.32.4)\n",
            "Requirement already satisfied: scikit-learn>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from nilearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from nilearn) (1.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.12/dist-packages (from nibabel>=5.2.0->nilearn) (4.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->nilearn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->nilearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->nilearn) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->nilearn) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->nilearn) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->nilearn) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->nilearn) (2025.11.12)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.4.0->nilearn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->nilearn) (1.17.0)\n",
            "Downloading neuroHarmonize-2.4.5-py3-none-any.whl (16 kB)\n",
            "Downloading nilearn-0.12.1-py3-none-any.whl (12.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m137.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: neuroHarmonize, nilearn\n",
            "Successfully installed neuroHarmonize-2.4.5 nilearn-0.12.1\n",
            "Requirement already satisfied: neuroHarmonize in /usr/local/lib/python3.12/dist-packages (2.4.5)\n",
            "Collecting neuroCombat\n",
            "  Downloading neuroCombat-0.2.12.tar.gz (6.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: neuroCombat\n",
            "  Building wheel for neuroCombat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neuroCombat: filename=neuroCombat-0.2.12-py3-none-any.whl size=6353 sha256=2ce8d7b31d69ca1289f8f256c48024c8c4af33faccbc764ceccb30028d9f75f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/6a/95/9d827c0f3cc23854b5fbd00fbc8a052d492538dc16bd20f7a2\n",
            "Successfully built neuroCombat\n",
            "Installing collected packages: neuroCombat\n",
            "Successfully installed neuroCombat-0.2.12\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install monai nibabel numpy scipy matplotlib tqdm SimpleITK\n",
        "!pip install neuroHarmonize nilearn tqdm\n",
        "!pip install neuroHarmonize neuroCombat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import SimpleITK as sitk\n",
        "import pandas as pd\n",
        "from nilearn import datasets, image, masking\n",
        "from tqdm import tqdm\n",
        "from neuroHarmonize import harmonizationLearn\n",
        "import seaborn as sns\n",
        "import imageio\n",
        "import tensorflow as tf\n",
        "from glob import glob\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "T40allWQnPJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeXGC4gHnc3U",
        "outputId": "cc08c0f5-e95f-47c0-8f50-dc6d57b01cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data\n",
        "HH_dir = \"/content/drive/MyDrive/finalT1T2Data/T2_train_by_loc/HH/\"\n",
        "guys_dir = \"/content/drive/MyDrive/finalT1T2Data/T2_train_by_loc/Guys/\"\n",
        "train_dir = \"/content/drive/MyDrive/finalT1T2Data/train_w_loc/T2\"\n",
        "\n",
        "\n",
        "train_prediction_files = sorted([f for f in os.listdir(train_dir)])\n",
        "hh_train_predictions_names = []\n",
        "guys_train_predictions_names= []\n",
        "for f in train_prediction_files:\n",
        "  f_full_name = os.path.join(train_dir, f)\n",
        "  img = Image.open(f_full_name)\n",
        "  if f_full_name.split('_')[3] == 'HH':\n",
        "    img.save(HH_dir + f)\n",
        "  else:\n",
        "    img.save(guys_dir + f)"
      ],
      "metadata": {
        "id": "IcGQH4RStHNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing data\n",
        "HH_dir = \"/content/drive/MyDrive/finalT1T2Data/T2_test_by_loc/HH/\"\n",
        "guys_dir = \"/content/drive/MyDrive/finalT1T2Data/T2_test_by_loc/Guys/\"\n",
        "test_dir = \"/content/drive/MyDrive/finalT1T2Data/test_w_loc/T2\"\n",
        "\n",
        "\n",
        "test_prediction_files = sorted([f for f in os.listdir(test_dir)])\n",
        "hh_test_predictions_names = []\n",
        "guys_test_predictions_names= []\n",
        "for f in test_prediction_files:\n",
        "  f_full_name = os.path.join(test_dir, f)\n",
        "  img = Image.open(f_full_name)\n",
        "  if f_full_name.split('_')[3] == 'HH':\n",
        "    img.save(HH_dir + f)\n",
        "  else:\n",
        "    img.save(guys_dir + f)"
      ],
      "metadata": {
        "id": "oLtr-_DAExyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train CycleGAN model to convert Guys T2 scans into the style of HH T2 scans."
      ],
      "metadata": {
        "id": "sBwD3o8J8Fzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CycleGAN\n",
        "\n",
        "import os\n",
        "import random\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "# parameters\n",
        "siteA_path = \"/content/drive/MyDrive/finalT1T2Data/T2_train_by_loc/Guys/\"   # source domain\n",
        "siteB_path = \"/content/drive/MyDrive/finalT1T2Data/T2_train_by_loc/HH/\"   # target domain\n",
        "out_dir = \"/content/drive/MyDrive/finalT1T2Data/outputs/harmonized_Guys_train\"\n",
        "checkpoints_dir = \"checkpoints/cyclegan\"\n",
        "sample_dir = \"samples\"\n",
        "img_size = 256\n",
        "batch_size = 4\n",
        "epochs = 100\n",
        "lr = 2e-4\n",
        "beta1 = 0.5\n",
        "lambda_cycle = 10.0\n",
        "lambda_id = 5.0\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "save_every = 10\n",
        "seed = 42\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "os.makedirs(checkpoints_dir, exist_ok=True)\n",
        "os.makedirs(sample_dir, exist_ok=True)\n",
        "\n",
        "# Dataset\n",
        "class PNGSliceDataset(Dataset):\n",
        "    def __init__(self, folder, img_size=256):\n",
        "        paths = sorted([p for p in glob(os.path.join(folder, \"*.png\")) if os.path.isfile(p)])\n",
        "        if len(paths) == 0:\n",
        "            raise RuntimeError(f\"No PNGs found in {folder}\")\n",
        "        self.paths = paths\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Grayscale(num_output_channels=1),\n",
        "            transforms.Resize((img_size, img_size), interpolation=Image.BILINEAR),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "    def __getitem__(self, idx):\n",
        "        p = self.paths[idx]\n",
        "        img = Image.open(p)\n",
        "        img = self.transform(img)\n",
        "        return img, p\n",
        "\n",
        "dsA = PNGSliceDataset(siteA_path, img_size=img_size)\n",
        "dsB = PNGSliceDataset(siteB_path, img_size=img_size)\n",
        "\n",
        "loaderA = DataLoader(dsA, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=2)\n",
        "loaderB = DataLoader(dsB, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=2)\n",
        "\n",
        "print(\"Num A:\", len(dsA), \"Num B:\", len(dsB), \"Device:\", device)\n",
        "\n",
        "#Utils\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "# Replay buffer for generated images\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, max_size=50):\n",
        "        assert max_size > 0\n",
        "        self.max_size = max_size\n",
        "        self.data = []\n",
        "    def push_and_pop(self, data):\n",
        "        to_return = []\n",
        "        for element in data:\n",
        "            element = element.unsqueeze(0)\n",
        "            if len(self.data) < self.max_size:\n",
        "                self.data.append(element)\n",
        "                to_return.append(element)\n",
        "            else:\n",
        "                if random.random() > 0.5:\n",
        "                    i = random.randint(0, self.max_size - 1)\n",
        "                    tmp = self.data[i].clone()\n",
        "                    self.data[i] = element\n",
        "                    to_return.append(tmp)\n",
        "                else:\n",
        "                    to_return.append(element)\n",
        "        return torch.cat(to_return, dim=0)\n",
        "\n",
        "# Save side-by-side samples\n",
        "def save_sample(epoch, batch_idx, real_A, real_B, fake_B, fake_A, prefix=\"sample\"):\n",
        "    B = min(4, real_A.shape[0])\n",
        "    import matplotlib.pyplot as plt\n",
        "    fig, axes = plt.subplots(B, 4, figsize=(12, 3*B))\n",
        "    for i in range(B):\n",
        "        axes[i,0].imshow(real_A[i,0].cpu().numpy(), cmap='gray'); axes[i,0].set_title(\"A (src)\")\n",
        "        axes[i,1].imshow(fake_B[i,0].cpu().numpy(), cmap='gray'); axes[i,1].set_title(\"A -> B\")\n",
        "        axes[i,2].imshow(real_B[i,0].cpu().numpy(), cmap='gray'); axes[i,2].set_title(\"B (tgt)\")\n",
        "        axes[i,3].imshow(fake_A[i,0].cpu().numpy(), cmap='gray'); axes[i,3].set_title(\"B -> A\")\n",
        "        for j in range(4):\n",
        "            axes[i,j].axis('off')\n",
        "    plt.tight_layout()\n",
        "    fname = os.path.join(sample_dir, f\"{prefix}_epoch{epoch:03d}_batch{batch_idx}.png\")\n",
        "    plt.savefig(fname, bbox_inches='tight', dpi=150)\n",
        "    plt.close(fig)\n",
        "\n",
        "# ----------------- Models ----------------\n",
        "# ResNet block used in generator\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(dim, dim, kernel_size=3, padding=0),\n",
        "            nn.InstanceNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(dim, dim, kernel_size=3, padding=0),\n",
        "            nn.InstanceNorm2d(dim),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return x + self.conv_block(x)\n",
        "\n",
        "# Generator\n",
        "class ResnetGenerator(nn.Module):\n",
        "    def __init__(self, input_nc=1, output_nc=1, ngf=64, n_blocks=6):\n",
        "        super().__init__()\n",
        "        model = []\n",
        "        model += [nn.ReflectionPad2d(3),\n",
        "                  nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0),\n",
        "                  nn.InstanceNorm2d(ngf),\n",
        "                  nn.ReLU(True)]\n",
        "        # downsample\n",
        "        n_downsampling = 2\n",
        "        mult = 1\n",
        "        for i in range(n_downsampling):\n",
        "            mult_prev = mult\n",
        "            mult = mult * 2\n",
        "            model += [nn.Conv2d(ngf * mult_prev, ngf * mult, kernel_size=3, stride=2, padding=1),\n",
        "                      nn.InstanceNorm2d(ngf * mult),\n",
        "                      nn.ReLU(True)]\n",
        "        # resnet blocks\n",
        "        for i in range(n_blocks):\n",
        "            model += [ResnetBlock(ngf * mult)]\n",
        "        # upsample\n",
        "        for i in range(n_downsampling):\n",
        "            mult_prev = mult\n",
        "            mult = mult // 2\n",
        "            model += [nn.ConvTranspose2d(ngf * mult_prev, ngf * mult, kernel_size=3, stride=2,\n",
        "                                         padding=1, output_padding=1),\n",
        "                      nn.InstanceNorm2d(ngf * mult),\n",
        "                      nn.ReLU(True)]\n",
        "        model += [nn.ReflectionPad2d(3),\n",
        "                  nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0),\n",
        "                  nn.Tanh()]\n",
        "        self.model = nn.Sequential(*model)\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# PatchGAN discriminator\n",
        "class NLayerDiscriminator(nn.Module):\n",
        "    def __init__(self, input_nc=1, ndf=64, n_layers=3):\n",
        "        super().__init__()\n",
        "        sequence = [\n",
        "            nn.Conv2d(input_nc, ndf, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        ]\n",
        "        nf_mult = 1\n",
        "        nf_mult_prev = 1\n",
        "        for n in range(1, n_layers):\n",
        "            nf_mult_prev = nf_mult\n",
        "            nf_mult = min(2**n, 8)\n",
        "            sequence += [\n",
        "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=4, stride=2, padding=1),\n",
        "                nn.InstanceNorm2d(ndf * nf_mult),\n",
        "                nn.LeakyReLU(0.2, True)\n",
        "            ]\n",
        "        nf_mult_prev = nf_mult\n",
        "        nf_mult = min(2**n_layers, 8)\n",
        "        sequence += [\n",
        "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=4, stride=1, padding=1),\n",
        "            nn.InstanceNorm2d(ndf * nf_mult),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        ]\n",
        "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=4, stride=1, padding=1)]\n",
        "        self.model = nn.Sequential(*sequence)\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# ----------------- Initialize models ----------------\n",
        "G_AB = ResnetGenerator().to(device)\n",
        "G_BA = ResnetGenerator().to(device)\n",
        "D_A = NLayerDiscriminator().to(device)\n",
        "D_B = NLayerDiscriminator().to(device)\n",
        "\n",
        "G_AB.apply(weights_init_normal)\n",
        "G_BA.apply(weights_init_normal)\n",
        "D_A.apply(weights_init_normal)\n",
        "D_B.apply(weights_init_normal)\n",
        "\n",
        "# Losses\n",
        "criterion_GAN = nn.MSELoss()\n",
        "criterion_cycle = nn.L1Loss()\n",
        "criterion_identity = nn.L1Loss()\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(list(G_AB.parameters()) + list(G_BA.parameters()), lr=lr, betas=(beta1, 0.999))\n",
        "optimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "# LR schedulers (linear decay after half epochs)\n",
        "def lambda_rule(epoch):\n",
        "    return 1.0 - max(0, epoch - epochs/2) / (epochs/2)\n",
        "scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lambda_rule)\n",
        "scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=lambda_rule)\n",
        "scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=lambda_rule)\n",
        "\n",
        "fake_A_buffer = ReplayBuffer()\n",
        "fake_B_buffer = ReplayBuffer()\n",
        "\n",
        "# target labels for LSGAN\n",
        "def real_target_like(x):\n",
        "    return torch.ones_like(x, device=device)\n",
        "def fake_target_like(x):\n",
        "    return torch.zeros_like(x, device=device)\n",
        "\n",
        "# Training loop\n",
        "print(\"Starting training...\")\n",
        "start_time = time.time()\n",
        "for epoch in range(1, epochs+1):\n",
        "    G_AB.train(); G_BA.train(); D_A.train(); D_B.train()\n",
        "    loop = tqdm(zip(loaderA, loaderB), total=min(len(loaderA), len(loaderB)))\n",
        "    recon_cycle_loss = 0.0\n",
        "    gan_loss_val = 0.0\n",
        "    id_loss_val = 0.0\n",
        "\n",
        "    for i, ((real_A, pathA), (real_B, pathB)) in enumerate(loop):\n",
        "        real_A = real_A.to(device) * 2.0 - 1.0\n",
        "        real_B = real_B.to(device) * 2.0 - 1.0\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        same_B = G_AB(real_B)\n",
        "        loss_id_B = criterion_identity(same_B, real_B) * lambda_cycle * lambda_id\n",
        "        same_A = G_BA(real_A)\n",
        "        loss_id_A = criterion_identity(same_A, real_A) * lambda_cycle * lambda_id\n",
        "\n",
        "        # GAN loss\n",
        "        fake_B = G_AB(real_A)\n",
        "        pred_fake_B = D_B(fake_B)\n",
        "        loss_GAN_AB = criterion_GAN(pred_fake_B, real_target_like(pred_fake_B))\n",
        "\n",
        "        fake_A = G_BA(real_B)\n",
        "        pred_fake_A = D_A(fake_A)\n",
        "        loss_GAN_BA = criterion_GAN(pred_fake_A, real_target_like(pred_fake_A))\n",
        "\n",
        "        # cycle loss\n",
        "        rec_A = G_BA(fake_B)\n",
        "        loss_cycle_A = criterion_cycle(rec_A, real_A) * lambda_cycle\n",
        "        rec_B = G_AB(fake_A)\n",
        "        loss_cycle_B = criterion_cycle(rec_B, real_B) * lambda_cycle\n",
        "\n",
        "        # total generator loss\n",
        "        loss_G = loss_GAN_AB + loss_GAN_BA + loss_cycle_A + loss_cycle_B + loss_id_A + loss_id_B\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        optimizer_D_B.zero_grad()\n",
        "        # Real\n",
        "        pred_real_B = D_B(real_B)\n",
        "        loss_D_real_B = criterion_GAN(pred_real_B, real_target_like(pred_real_B))\n",
        "        # Fake\n",
        "        fake_B_detached = fake_B_buffer.push_and_pop(fake_B.detach())\n",
        "        pred_fake_B = D_B(fake_B_detached)\n",
        "        loss_D_fake_B = criterion_GAN(pred_fake_B, fake_target_like(pred_fake_B))\n",
        "        loss_D_B = (loss_D_real_B + loss_D_fake_B) * 0.5\n",
        "        loss_D_B.backward()\n",
        "        optimizer_D_B.step()\n",
        "\n",
        "        optimizer_D_A.zero_grad()\n",
        "        pred_real_A = D_A(real_A)\n",
        "        loss_D_real_A = criterion_GAN(pred_real_A, real_target_like(pred_real_A))\n",
        "        fake_A_detached = fake_A_buffer.push_and_pop(fake_A.detach())\n",
        "        pred_fake_A = D_A(fake_A_detached)\n",
        "        loss_D_fake_A = criterion_GAN(pred_fake_A, fake_target_like(pred_fake_A))\n",
        "        loss_D_A = (loss_D_real_A + loss_D_fake_A) * 0.5\n",
        "        loss_D_A.backward()\n",
        "        optimizer_D_A.step()\n",
        "\n",
        "        # logging\n",
        "        recon_cycle_loss += (loss_cycle_A.item() + loss_cycle_B.item())\n",
        "        gan_loss_val += (loss_GAN_AB.item() + loss_GAN_BA.item())\n",
        "        id_loss_val += (loss_id_A.item() + loss_id_B.item())\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            loop.set_description(f\"Epoch[{epoch}/{epochs}] step {i} lossG {loss_G.item():.4f}\")\n",
        "\n",
        "    # update lr\n",
        "    scheduler_G.step()\n",
        "    scheduler_D_A.step()\n",
        "    scheduler_D_B.step()\n",
        "\n",
        "    # Save samples & checkpoint\n",
        "    if epoch % save_every == 0 or epoch == 1 or epoch == epochs:\n",
        "        with torch.no_grad():\n",
        "            G_AB.eval(); G_BA.eval()\n",
        "            real_A_sample, _ = next(iter(loaderA))\n",
        "            real_B_sample, _ = next(iter(loaderB))\n",
        "            real_A_sample = real_A_sample.to(device) * 2.0 - 1.0\n",
        "            real_B_sample = real_B_sample.to(device) * 2.0 - 1.0\n",
        "            fake_B_sample = G_AB(real_A_sample).cpu() * 0.5 + 0.5\n",
        "            fake_A_sample = G_BA(real_B_sample).cpu() * 0.5 + 0.5\n",
        "            real_A_vis = (real_A_sample.cpu() * 0.5 + 0.5)\n",
        "            real_B_vis = (real_B_sample.cpu() * 0.5 + 0.5)\n",
        "            save_sample(epoch, 0, real_A_vis, real_B_vis, fake_B_sample, fake_A_sample, prefix=\"epoch\")\n",
        "        torch.save({\n",
        "            'G_AB': G_AB.state_dict(),\n",
        "            'G_BA': G_BA.state_dict(),\n",
        "            'D_A': D_A.state_dict(),\n",
        "            'D_B': D_B.state_dict(),\n",
        "            'optimizer_G': optimizer_G.state_dict(),\n",
        "            'optimizer_D_A': optimizer_D_A.state_dict(),\n",
        "            'optimizer_D_B': optimizer_D_B.state_dict(),\n",
        "        }, os.path.join(checkpoints_dir, f\"cyclegan_epoch{epoch:03d}.pth\"))\n",
        "        print(f\"[Epoch {epoch}] Saved samples and checkpoint.\")\n",
        "\n",
        "\n",
        "    print(f\"Epoch {epoch} summary: cycle_loss {recon_cycle_loss/len(loaderA):.6f}, gan_loss {gan_loss_val/len(loaderA):.6f}, id_loss {id_loss_val/len(loaderA):.6f}\")\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "print(\"Training finished in {:.1f} s\".format(elapsed))\n",
        "\n",
        "\n",
        "# Save final trained models\n",
        "torch.save({\n",
        "    'G_AB': G_AB.state_dict(),\n",
        "    'G_BA': G_BA.state_dict(),\n",
        "    'D_A': D_A.state_dict(),\n",
        "    'D_B': D_B.state_dict(),\n",
        "    'optimizer_G': optimizer_G.state_dict(),\n",
        "    'optimizer_D_A': optimizer_D_A.state_dict(),\n",
        "    'optimizer_D_B': optimizer_D_B.state_dict(),\n",
        "    'epochs': epochs,\n",
        "}, os.path.join(checkpoints_dir, \"cyclegan_final_T2.pth\"))\n",
        "\n",
        "print(\"Final model saved to:\", os.path.join(checkpoints_dir, \"cyclegan_final_T2.pth\"))\n",
        "# Harmonize Guys Images\n",
        "print(\"Generating harmonized outputs for Site A ...\")\n",
        "G_AB.eval()\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "with torch.no_grad():\n",
        "    for i in range(len(dsA)):\n",
        "        x, p = dsA[i]\n",
        "        x_t = x.unsqueeze(0).to(device) * 2.0 - 1.0\n",
        "        y = G_AB(x_t)              # in [-1,1]\n",
        "        y = (y.cpu().squeeze(0).squeeze(0).numpy() * 0.5 + 0.5)  # to [0,1]\n",
        "        y = (np.clip(y, 0.0, 1.0) * 255.0).astype(np.uint8)\n",
        "        fname = os.path.basename(p)\n",
        "        Image.fromarray(y).save(os.path.join(out_dir, fname))\n",
        "print(\"Harmonized images saved to:\", out_dir)\n",
        "\n"
      ],
      "metadata": {
        "id": "p5V1CdNY8MZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc139a18-b27e-4865-c617-916323a41ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num A: 88 Num B: 88 Device: cuda\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[1/100] step 0 lossG 91.6746: 100%|██████████| 22/22 [00:35<00:00,  1.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] Saved samples and checkpoint.\n",
            "Epoch 1 summary: cycle_loss 3.586406, gan_loss 2.814836, id_loss 16.389591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[2/100] step 0 lossG 9.5419: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 summary: cycle_loss 1.390958, gan_loss 0.813554, id_loss 6.209581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[3/100] step 0 lossG 9.1867: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 summary: cycle_loss 1.216699, gan_loss 0.927505, id_loss 5.426962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[4/100] step 0 lossG 10.0016: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 summary: cycle_loss 1.118034, gan_loss 1.005137, id_loss 5.087021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[5/100] step 0 lossG 6.6033: 100%|██████████| 22/22 [00:34<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 summary: cycle_loss 1.058201, gan_loss 0.687178, id_loss 4.696841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[6/100] step 0 lossG 6.2938: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 summary: cycle_loss 0.944238, gan_loss 0.691350, id_loss 4.168956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[7/100] step 0 lossG 5.8513: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 summary: cycle_loss 0.917112, gan_loss 0.744738, id_loss 4.068358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[8/100] step 0 lossG 4.4617: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 summary: cycle_loss 0.905884, gan_loss 0.684993, id_loss 4.000972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[9/100] step 0 lossG 4.9838: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 summary: cycle_loss 0.857832, gan_loss 0.788817, id_loss 3.766214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[10/100] step 0 lossG 5.0794: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 10] Saved samples and checkpoint.\n",
            "Epoch 10 summary: cycle_loss 0.863406, gan_loss 0.709713, id_loss 3.725508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[11/100] step 0 lossG 6.1929: 100%|██████████| 22/22 [00:34<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 summary: cycle_loss 0.883533, gan_loss 0.815495, id_loss 3.846229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[12/100] step 0 lossG 4.7099: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 summary: cycle_loss 0.781496, gan_loss 0.716779, id_loss 3.373888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[13/100] step 0 lossG 5.0239: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 summary: cycle_loss 0.798290, gan_loss 0.822840, id_loss 3.481079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[14/100] step 0 lossG 4.8773: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 summary: cycle_loss 0.810466, gan_loss 0.760694, id_loss 3.422975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[15/100] step 0 lossG 4.5227: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 summary: cycle_loss 0.794899, gan_loss 0.879742, id_loss 3.420353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[16/100] step 0 lossG 4.3635: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 summary: cycle_loss 0.783273, gan_loss 0.769302, id_loss 3.464107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[17/100] step 0 lossG 5.3711: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 summary: cycle_loss 0.738704, gan_loss 0.839019, id_loss 3.196856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[18/100] step 0 lossG 5.3882: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 summary: cycle_loss 0.740911, gan_loss 0.856346, id_loss 3.181674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[19/100] step 0 lossG 4.6259: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 summary: cycle_loss 0.725962, gan_loss 0.825928, id_loss 3.132970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[20/100] step 0 lossG 4.6282: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 20] Saved samples and checkpoint.\n",
            "Epoch 20 summary: cycle_loss 0.714673, gan_loss 0.957064, id_loss 3.119898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[21/100] step 0 lossG 5.5679: 100%|██████████| 22/22 [00:34<00:00,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 summary: cycle_loss 0.720019, gan_loss 0.851345, id_loss 3.105688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[22/100] step 0 lossG 4.9353: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 summary: cycle_loss 0.699543, gan_loss 0.856070, id_loss 3.049435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[23/100] step 0 lossG 4.2088: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 summary: cycle_loss 0.746669, gan_loss 0.903203, id_loss 3.247403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[24/100] step 0 lossG 4.3440: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 summary: cycle_loss 0.689717, gan_loss 0.924589, id_loss 2.963362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[25/100] step 0 lossG 3.7047: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 summary: cycle_loss 0.715328, gan_loss 0.917613, id_loss 3.012723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[26/100] step 0 lossG 4.4226: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 summary: cycle_loss 0.704438, gan_loss 0.844102, id_loss 2.965061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[27/100] step 0 lossG 4.0921: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 summary: cycle_loss 0.725413, gan_loss 0.876128, id_loss 3.048993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[28/100] step 0 lossG 4.1938: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 summary: cycle_loss 0.673003, gan_loss 0.863293, id_loss 2.804403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[29/100] step 0 lossG 4.7883: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 summary: cycle_loss 0.716456, gan_loss 0.886456, id_loss 2.920708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[30/100] step 0 lossG 4.3336: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 30] Saved samples and checkpoint.\n",
            "Epoch 30 summary: cycle_loss 0.678628, gan_loss 0.894632, id_loss 2.848612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[31/100] step 0 lossG 4.8976: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31 summary: cycle_loss 0.675041, gan_loss 0.890957, id_loss 2.707739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[32/100] step 0 lossG 4.1874: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32 summary: cycle_loss 0.666647, gan_loss 0.884747, id_loss 2.686151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[33/100] step 0 lossG 3.7629: 100%|██████████| 22/22 [00:34<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33 summary: cycle_loss 0.682866, gan_loss 0.957237, id_loss 2.749506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[34/100] step 0 lossG 3.9368: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34 summary: cycle_loss 0.687491, gan_loss 0.914576, id_loss 2.868227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[35/100] step 0 lossG 4.2249: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 summary: cycle_loss 0.674511, gan_loss 0.849781, id_loss 2.807894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[36/100] step 0 lossG 3.8882: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36 summary: cycle_loss 0.674160, gan_loss 0.842993, id_loss 2.743764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[37/100] step 0 lossG 4.5483: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37 summary: cycle_loss 0.689621, gan_loss 0.795619, id_loss 2.736172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[38/100] step 0 lossG 3.8054: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38 summary: cycle_loss 0.687982, gan_loss 0.788706, id_loss 2.735703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[39/100] step 0 lossG 3.8738: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39 summary: cycle_loss 0.702295, gan_loss 0.747933, id_loss 2.821187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[40/100] step 0 lossG 4.0550: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 40] Saved samples and checkpoint.\n",
            "Epoch 40 summary: cycle_loss 0.638843, gan_loss 0.771822, id_loss 2.551444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[41/100] step 0 lossG 3.1768: 100%|██████████| 22/22 [00:34<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41 summary: cycle_loss 0.636308, gan_loss 0.749141, id_loss 2.668770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[42/100] step 0 lossG 3.6338: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42 summary: cycle_loss 0.616525, gan_loss 0.816825, id_loss 2.557232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[43/100] step 0 lossG 4.3393: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43 summary: cycle_loss 0.601918, gan_loss 0.823290, id_loss 2.397454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[44/100] step 0 lossG 3.8039: 100%|██████████| 22/22 [00:34<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44 summary: cycle_loss 0.654464, gan_loss 0.763816, id_loss 2.579631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[45/100] step 0 lossG 4.6038: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45 summary: cycle_loss 0.675101, gan_loss 0.889107, id_loss 2.909375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[46/100] step 0 lossG 4.9208: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46 summary: cycle_loss 0.631466, gan_loss 0.760449, id_loss 2.591204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[47/100] step 0 lossG 4.0079: 100%|██████████| 22/22 [00:34<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47 summary: cycle_loss 0.627122, gan_loss 0.892864, id_loss 2.517376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[48/100] step 0 lossG 3.6977: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48 summary: cycle_loss 0.616676, gan_loss 0.748031, id_loss 2.495442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[49/100] step 0 lossG 3.6419: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49 summary: cycle_loss 0.614120, gan_loss 0.811713, id_loss 2.422513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[50/100] step 0 lossG 3.8954: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 50] Saved samples and checkpoint.\n",
            "Epoch 50 summary: cycle_loss 0.612226, gan_loss 0.807035, id_loss 2.442504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[51/100] step 0 lossG 3.5170: 100%|██████████| 22/22 [00:34<00:00,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51 summary: cycle_loss 0.574205, gan_loss 0.867927, id_loss 2.297173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[52/100] step 0 lossG 4.3125: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52 summary: cycle_loss 0.574663, gan_loss 0.776985, id_loss 2.351836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[53/100] step 0 lossG 3.8341: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53 summary: cycle_loss 0.611412, gan_loss 0.820595, id_loss 2.436349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[54/100] step 0 lossG 3.6217: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54 summary: cycle_loss 0.592825, gan_loss 0.810146, id_loss 2.352436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[55/100] step 0 lossG 2.9268: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55 summary: cycle_loss 0.567210, gan_loss 0.812313, id_loss 2.275653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[56/100] step 0 lossG 3.5898: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56 summary: cycle_loss 0.567458, gan_loss 0.831162, id_loss 2.254680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[57/100] step 0 lossG 4.5515: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57 summary: cycle_loss 0.598342, gan_loss 0.825683, id_loss 2.365738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[58/100] step 0 lossG 3.1118: 100%|██████████| 22/22 [00:34<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58 summary: cycle_loss 0.556264, gan_loss 0.814017, id_loss 2.174394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[59/100] step 0 lossG 3.3286: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59 summary: cycle_loss 0.578331, gan_loss 0.822392, id_loss 2.215911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[60/100] step 0 lossG 3.8363: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 60] Saved samples and checkpoint.\n",
            "Epoch 60 summary: cycle_loss 0.535865, gan_loss 0.820734, id_loss 2.075615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[61/100] step 0 lossG 3.5146: 100%|██████████| 22/22 [00:34<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61 summary: cycle_loss 0.548614, gan_loss 0.840535, id_loss 2.181411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[62/100] step 0 lossG 3.4814: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62 summary: cycle_loss 0.559878, gan_loss 0.837263, id_loss 2.194775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[63/100] step 0 lossG 3.7269: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63 summary: cycle_loss 0.519999, gan_loss 0.818658, id_loss 2.063731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[64/100] step 0 lossG 3.2146: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64 summary: cycle_loss 0.522433, gan_loss 0.829603, id_loss 2.004435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[65/100] step 0 lossG 3.7471: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65 summary: cycle_loss 0.551610, gan_loss 0.864363, id_loss 2.186168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[66/100] step 0 lossG 3.3085: 100%|██████████| 22/22 [00:34<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66 summary: cycle_loss 0.499021, gan_loss 0.856802, id_loss 1.989609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[67/100] step 0 lossG 3.4882: 100%|██████████| 22/22 [00:34<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67 summary: cycle_loss 0.520713, gan_loss 0.843907, id_loss 1.985258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[68/100] step 0 lossG 3.7437: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68 summary: cycle_loss 0.507167, gan_loss 0.854364, id_loss 1.917743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[69/100] step 0 lossG 3.7097: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69 summary: cycle_loss 0.504035, gan_loss 0.825192, id_loss 1.885531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[70/100] step 0 lossG 4.1907: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 70] Saved samples and checkpoint.\n",
            "Epoch 70 summary: cycle_loss 0.518171, gan_loss 0.847078, id_loss 2.022363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[71/100] step 0 lossG 2.8761: 100%|██████████| 22/22 [00:34<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71 summary: cycle_loss 0.509860, gan_loss 0.847382, id_loss 1.902926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[72/100] step 0 lossG 2.7179: 100%|██████████| 22/22 [00:34<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72 summary: cycle_loss 0.515673, gan_loss 0.842711, id_loss 1.924443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[73/100] step 0 lossG 3.5915: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73 summary: cycle_loss 0.493038, gan_loss 0.840612, id_loss 1.815014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[74/100] step 0 lossG 2.5652: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74 summary: cycle_loss 0.493244, gan_loss 0.848412, id_loss 1.861947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[75/100] step 0 lossG 3.3919: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75 summary: cycle_loss 0.485748, gan_loss 0.835925, id_loss 1.811859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[76/100] step 0 lossG 3.0678: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76 summary: cycle_loss 0.496379, gan_loss 0.819417, id_loss 1.788372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[77/100] step 0 lossG 3.1881: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77 summary: cycle_loss 0.508855, gan_loss 0.803930, id_loss 1.810641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[78/100] step 0 lossG 2.9829: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78 summary: cycle_loss 0.502927, gan_loss 0.805862, id_loss 1.752049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[79/100] step 0 lossG 3.2441: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79 summary: cycle_loss 0.482914, gan_loss 0.796768, id_loss 1.723908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[80/100] step 0 lossG 3.3487: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 80] Saved samples and checkpoint.\n",
            "Epoch 80 summary: cycle_loss 0.484864, gan_loss 0.818945, id_loss 1.715877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[81/100] step 0 lossG 2.4347: 100%|██████████| 22/22 [00:34<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81 summary: cycle_loss 0.480492, gan_loss 0.794230, id_loss 1.680772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[82/100] step 0 lossG 2.9226: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82 summary: cycle_loss 0.505875, gan_loss 0.769242, id_loss 1.718651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[83/100] step 0 lossG 2.8017: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83 summary: cycle_loss 0.480871, gan_loss 0.794326, id_loss 1.653011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[84/100] step 0 lossG 2.3937: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84 summary: cycle_loss 0.476469, gan_loss 0.778102, id_loss 1.626990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[85/100] step 0 lossG 2.8082: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85 summary: cycle_loss 0.469229, gan_loss 0.802814, id_loss 1.587704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[86/100] step 0 lossG 2.4478: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86 summary: cycle_loss 0.480084, gan_loss 0.770288, id_loss 1.570403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[87/100] step 0 lossG 3.1158: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87 summary: cycle_loss 0.474520, gan_loss 0.766903, id_loss 1.569225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[88/100] step 0 lossG 2.4548: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 88 summary: cycle_loss 0.466900, gan_loss 0.763022, id_loss 1.526323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[89/100] step 0 lossG 2.4103: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89 summary: cycle_loss 0.466682, gan_loss 0.753032, id_loss 1.486183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[90/100] step 0 lossG 2.4519: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 90] Saved samples and checkpoint.\n",
            "Epoch 90 summary: cycle_loss 0.471933, gan_loss 0.728078, id_loss 1.504049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[91/100] step 0 lossG 2.5897: 100%|██████████| 22/22 [00:34<00:00,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91 summary: cycle_loss 0.476077, gan_loss 0.760378, id_loss 1.466765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[92/100] step 0 lossG 2.4368: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92 summary: cycle_loss 0.451069, gan_loss 0.736352, id_loss 1.421306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[93/100] step 0 lossG 2.7706: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93 summary: cycle_loss 0.454577, gan_loss 0.724374, id_loss 1.396087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[94/100] step 0 lossG 3.3322: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94 summary: cycle_loss 0.455161, gan_loss 0.731094, id_loss 1.374155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[95/100] step 0 lossG 2.2387: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95 summary: cycle_loss 0.442894, gan_loss 0.735703, id_loss 1.366068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[96/100] step 0 lossG 2.4573: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96 summary: cycle_loss 0.434665, gan_loss 0.728723, id_loss 1.327112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[97/100] step 0 lossG 2.5025: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97 summary: cycle_loss 0.442074, gan_loss 0.721694, id_loss 1.334920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[98/100] step 0 lossG 2.2743: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98 summary: cycle_loss 0.434428, gan_loss 0.717795, id_loss 1.306365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[99/100] step 0 lossG 2.6251: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99 summary: cycle_loss 0.434293, gan_loss 0.718662, id_loss 1.284859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[100/100] step 0 lossG 2.4592: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 100] Saved samples and checkpoint.\n",
            "Epoch 100 summary: cycle_loss 0.428461, gan_loss 0.712813, id_loss 1.270243\n",
            "Training finished in 3460.8 s\n",
            "Final model saved to: checkpoints/cyclegan/cyclegan_final_T2.pth\n",
            "Generating harmonized outputs for Site A ...\n",
            "Harmonized images saved to: /content/drive/MyDrive/finalT1T2Data/outputs/harmonized_Guys_train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AzxKUq5Tjyrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ikyEY2lLjyoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2QGej8cujylH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train CycleGAN model to convert Guys T1 scans into the style of HH T1 scans."
      ],
      "metadata": {
        "id": "BjyJfHCl8VEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CycleGAN\n",
        "\n",
        "import os\n",
        "import random\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "# parameters\n",
        "siteA_path = \"/content/drive/MyDrive/finalT1T2Data/T1_train_by_loc/Guys/\"   # source domain\n",
        "siteB_path = \"/content/drive/MyDrive/finalT1T2Data/T1_train_by_loc/HH/\"   # target domain\n",
        "out_dir = \"/content/drive/MyDrive/finalT1T2Data/outputs/harmonized_Guys_train_T1\"\n",
        "checkpoints_dir = \"checkpoints/cyclegan\"\n",
        "sample_dir = \"samples\"\n",
        "img_size = 256\n",
        "batch_size = 4\n",
        "epochs = 100\n",
        "lr = 2e-4\n",
        "beta1 = 0.5\n",
        "lambda_cycle = 10.0\n",
        "lambda_id = 5.0\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "save_every = 10\n",
        "seed = 42\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "os.makedirs(checkpoints_dir, exist_ok=True)\n",
        "os.makedirs(sample_dir, exist_ok=True)\n",
        "\n",
        "# Dataset\n",
        "class PNGSliceDataset(Dataset):\n",
        "    def __init__(self, folder, img_size=256):\n",
        "        paths = sorted([p for p in glob(os.path.join(folder, \"*.png\")) if os.path.isfile(p)])\n",
        "        if len(paths) == 0:\n",
        "            raise RuntimeError(f\"No PNGs found in {folder}\")\n",
        "        self.paths = paths\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Grayscale(num_output_channels=1),\n",
        "            transforms.Resize((img_size, img_size), interpolation=Image.BILINEAR),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "    def __getitem__(self, idx):\n",
        "        p = self.paths[idx]\n",
        "        img = Image.open(p)\n",
        "        img = self.transform(img)\n",
        "        return img, p\n",
        "\n",
        "dsA = PNGSliceDataset(siteA_path, img_size=img_size)\n",
        "dsB = PNGSliceDataset(siteB_path, img_size=img_size)\n",
        "\n",
        "loaderA = DataLoader(dsA, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=2)\n",
        "loaderB = DataLoader(dsB, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=2)\n",
        "\n",
        "print(\"Num A:\", len(dsA), \"Num B:\", len(dsB), \"Device:\", device)\n",
        "\n",
        "#Utils\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "# Replay buffer for generated images\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, max_size=50):\n",
        "        assert max_size > 0\n",
        "        self.max_size = max_size\n",
        "        self.data = []\n",
        "    def push_and_pop(self, data):\n",
        "        to_return = []\n",
        "        for element in data:\n",
        "            element = element.unsqueeze(0)\n",
        "            if len(self.data) < self.max_size:\n",
        "                self.data.append(element)\n",
        "                to_return.append(element)\n",
        "            else:\n",
        "                if random.random() > 0.5:\n",
        "                    i = random.randint(0, self.max_size - 1)\n",
        "                    tmp = self.data[i].clone()\n",
        "                    self.data[i] = element\n",
        "                    to_return.append(tmp)\n",
        "                else:\n",
        "                    to_return.append(element)\n",
        "        return torch.cat(to_return, dim=0)\n",
        "\n",
        "# Save side-by-side samples\n",
        "def save_sample(epoch, batch_idx, real_A, real_B, fake_B, fake_A, prefix=\"sample\"):\n",
        "    B = min(4, real_A.shape[0])\n",
        "    import matplotlib.pyplot as plt\n",
        "    fig, axes = plt.subplots(B, 4, figsize=(12, 3*B))\n",
        "    for i in range(B):\n",
        "        axes[i,0].imshow(real_A[i,0].cpu().numpy(), cmap='gray'); axes[i,0].set_title(\"A (src)\")\n",
        "        axes[i,1].imshow(fake_B[i,0].cpu().numpy(), cmap='gray'); axes[i,1].set_title(\"A -> B\")\n",
        "        axes[i,2].imshow(real_B[i,0].cpu().numpy(), cmap='gray'); axes[i,2].set_title(\"B (tgt)\")\n",
        "        axes[i,3].imshow(fake_A[i,0].cpu().numpy(), cmap='gray'); axes[i,3].set_title(\"B -> A\")\n",
        "        for j in range(4):\n",
        "            axes[i,j].axis('off')\n",
        "    plt.tight_layout()\n",
        "    fname = os.path.join(sample_dir, f\"{prefix}_epoch{epoch:03d}_batch{batch_idx}.png\")\n",
        "    plt.savefig(fname, bbox_inches='tight', dpi=150)\n",
        "    plt.close(fig)\n",
        "\n",
        "# ----------------- Models ----------------\n",
        "# ResNet block used in generator\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(dim, dim, kernel_size=3, padding=0),\n",
        "            nn.InstanceNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(dim, dim, kernel_size=3, padding=0),\n",
        "            nn.InstanceNorm2d(dim),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return x + self.conv_block(x)\n",
        "\n",
        "# Generator\n",
        "class ResnetGenerator(nn.Module):\n",
        "    def __init__(self, input_nc=1, output_nc=1, ngf=64, n_blocks=6):\n",
        "        super().__init__()\n",
        "        model = []\n",
        "        model += [nn.ReflectionPad2d(3),\n",
        "                  nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0),\n",
        "                  nn.InstanceNorm2d(ngf),\n",
        "                  nn.ReLU(True)]\n",
        "        # downsample\n",
        "        n_downsampling = 2\n",
        "        mult = 1\n",
        "        for i in range(n_downsampling):\n",
        "            mult_prev = mult\n",
        "            mult = mult * 2\n",
        "            model += [nn.Conv2d(ngf * mult_prev, ngf * mult, kernel_size=3, stride=2, padding=1),\n",
        "                      nn.InstanceNorm2d(ngf * mult),\n",
        "                      nn.ReLU(True)]\n",
        "        # resnet blocks\n",
        "        for i in range(n_blocks):\n",
        "            model += [ResnetBlock(ngf * mult)]\n",
        "        # upsample\n",
        "        for i in range(n_downsampling):\n",
        "            mult_prev = mult\n",
        "            mult = mult // 2\n",
        "            model += [nn.ConvTranspose2d(ngf * mult_prev, ngf * mult, kernel_size=3, stride=2,\n",
        "                                         padding=1, output_padding=1),\n",
        "                      nn.InstanceNorm2d(ngf * mult),\n",
        "                      nn.ReLU(True)]\n",
        "        model += [nn.ReflectionPad2d(3),\n",
        "                  nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0),\n",
        "                  nn.Tanh()]\n",
        "        self.model = nn.Sequential(*model)\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# PatchGAN discriminator\n",
        "class NLayerDiscriminator(nn.Module):\n",
        "    def __init__(self, input_nc=1, ndf=64, n_layers=3):\n",
        "        super().__init__()\n",
        "        sequence = [\n",
        "            nn.Conv2d(input_nc, ndf, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        ]\n",
        "        nf_mult = 1\n",
        "        nf_mult_prev = 1\n",
        "        for n in range(1, n_layers):\n",
        "            nf_mult_prev = nf_mult\n",
        "            nf_mult = min(2**n, 8)\n",
        "            sequence += [\n",
        "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=4, stride=2, padding=1),\n",
        "                nn.InstanceNorm2d(ndf * nf_mult),\n",
        "                nn.LeakyReLU(0.2, True)\n",
        "            ]\n",
        "        nf_mult_prev = nf_mult\n",
        "        nf_mult = min(2**n_layers, 8)\n",
        "        sequence += [\n",
        "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=4, stride=1, padding=1),\n",
        "            nn.InstanceNorm2d(ndf * nf_mult),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        ]\n",
        "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=4, stride=1, padding=1)]\n",
        "        self.model = nn.Sequential(*sequence)\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# ----------------- Initialize models ----------------\n",
        "G_AB = ResnetGenerator().to(device)\n",
        "G_BA = ResnetGenerator().to(device)\n",
        "D_A = NLayerDiscriminator().to(device)\n",
        "D_B = NLayerDiscriminator().to(device)\n",
        "\n",
        "G_AB.apply(weights_init_normal)\n",
        "G_BA.apply(weights_init_normal)\n",
        "D_A.apply(weights_init_normal)\n",
        "D_B.apply(weights_init_normal)\n",
        "\n",
        "# Losses\n",
        "criterion_GAN = nn.MSELoss()\n",
        "criterion_cycle = nn.L1Loss()\n",
        "criterion_identity = nn.L1Loss()\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(list(G_AB.parameters()) + list(G_BA.parameters()), lr=lr, betas=(beta1, 0.999))\n",
        "optimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "# LR schedulers (linear decay after half epochs)\n",
        "def lambda_rule(epoch):\n",
        "    return 1.0 - max(0, epoch - epochs/2) / (epochs/2)\n",
        "scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lambda_rule)\n",
        "scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=lambda_rule)\n",
        "scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=lambda_rule)\n",
        "\n",
        "fake_A_buffer = ReplayBuffer()\n",
        "fake_B_buffer = ReplayBuffer()\n",
        "\n",
        "# target labels for LSGAN\n",
        "def real_target_like(x):\n",
        "    return torch.ones_like(x, device=device)\n",
        "def fake_target_like(x):\n",
        "    return torch.zeros_like(x, device=device)\n",
        "\n",
        "# Training loop\n",
        "print(\"Starting training...\")\n",
        "start_time = time.time()\n",
        "for epoch in range(1, epochs+1):\n",
        "    G_AB.train(); G_BA.train(); D_A.train(); D_B.train()\n",
        "    loop = tqdm(zip(loaderA, loaderB), total=min(len(loaderA), len(loaderB)))\n",
        "    recon_cycle_loss = 0.0\n",
        "    gan_loss_val = 0.0\n",
        "    id_loss_val = 0.0\n",
        "\n",
        "    for i, ((real_A, pathA), (real_B, pathB)) in enumerate(loop):\n",
        "        real_A = real_A.to(device) * 2.0 - 1.0\n",
        "        real_B = real_B.to(device) * 2.0 - 1.0\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        same_B = G_AB(real_B)\n",
        "        loss_id_B = criterion_identity(same_B, real_B) * lambda_cycle * lambda_id\n",
        "        same_A = G_BA(real_A)\n",
        "        loss_id_A = criterion_identity(same_A, real_A) * lambda_cycle * lambda_id\n",
        "\n",
        "        # GAN loss\n",
        "        fake_B = G_AB(real_A)\n",
        "        pred_fake_B = D_B(fake_B)\n",
        "        loss_GAN_AB = criterion_GAN(pred_fake_B, real_target_like(pred_fake_B))\n",
        "\n",
        "        fake_A = G_BA(real_B)\n",
        "        pred_fake_A = D_A(fake_A)\n",
        "        loss_GAN_BA = criterion_GAN(pred_fake_A, real_target_like(pred_fake_A))\n",
        "\n",
        "        # cycle loss\n",
        "        rec_A = G_BA(fake_B)\n",
        "        loss_cycle_A = criterion_cycle(rec_A, real_A) * lambda_cycle\n",
        "        rec_B = G_AB(fake_A)\n",
        "        loss_cycle_B = criterion_cycle(rec_B, real_B) * lambda_cycle\n",
        "\n",
        "        # total generator loss\n",
        "        loss_G = loss_GAN_AB + loss_GAN_BA + loss_cycle_A + loss_cycle_B + loss_id_A + loss_id_B\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        optimizer_D_B.zero_grad()\n",
        "        # Real\n",
        "        pred_real_B = D_B(real_B)\n",
        "        loss_D_real_B = criterion_GAN(pred_real_B, real_target_like(pred_real_B))\n",
        "        # Fake\n",
        "        fake_B_detached = fake_B_buffer.push_and_pop(fake_B.detach())\n",
        "        pred_fake_B = D_B(fake_B_detached)\n",
        "        loss_D_fake_B = criterion_GAN(pred_fake_B, fake_target_like(pred_fake_B))\n",
        "        loss_D_B = (loss_D_real_B + loss_D_fake_B) * 0.5\n",
        "        loss_D_B.backward()\n",
        "        optimizer_D_B.step()\n",
        "\n",
        "        optimizer_D_A.zero_grad()\n",
        "        pred_real_A = D_A(real_A)\n",
        "        loss_D_real_A = criterion_GAN(pred_real_A, real_target_like(pred_real_A))\n",
        "        fake_A_detached = fake_A_buffer.push_and_pop(fake_A.detach())\n",
        "        pred_fake_A = D_A(fake_A_detached)\n",
        "        loss_D_fake_A = criterion_GAN(pred_fake_A, fake_target_like(pred_fake_A))\n",
        "        loss_D_A = (loss_D_real_A + loss_D_fake_A) * 0.5\n",
        "        loss_D_A.backward()\n",
        "        optimizer_D_A.step()\n",
        "\n",
        "        # logging\n",
        "        recon_cycle_loss += (loss_cycle_A.item() + loss_cycle_B.item())\n",
        "        gan_loss_val += (loss_GAN_AB.item() + loss_GAN_BA.item())\n",
        "        id_loss_val += (loss_id_A.item() + loss_id_B.item())\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            loop.set_description(f\"Epoch[{epoch}/{epochs}] step {i} lossG {loss_G.item():.4f}\")\n",
        "\n",
        "    # update lr\n",
        "    scheduler_G.step()\n",
        "    scheduler_D_A.step()\n",
        "    scheduler_D_B.step()\n",
        "\n",
        "    # Save samples & checkpoint\n",
        "    if epoch % save_every == 0 or epoch == 1 or epoch == epochs:\n",
        "        with torch.no_grad():\n",
        "            G_AB.eval(); G_BA.eval()\n",
        "            real_A_sample, _ = next(iter(loaderA))\n",
        "            real_B_sample, _ = next(iter(loaderB))\n",
        "            real_A_sample = real_A_sample.to(device) * 2.0 - 1.0\n",
        "            real_B_sample = real_B_sample.to(device) * 2.0 - 1.0\n",
        "            fake_B_sample = G_AB(real_A_sample).cpu() * 0.5 + 0.5\n",
        "            fake_A_sample = G_BA(real_B_sample).cpu() * 0.5 + 0.5\n",
        "            real_A_vis = (real_A_sample.cpu() * 0.5 + 0.5)\n",
        "            real_B_vis = (real_B_sample.cpu() * 0.5 + 0.5)\n",
        "            save_sample(epoch, 0, real_A_vis, real_B_vis, fake_B_sample, fake_A_sample, prefix=\"epoch\")\n",
        "        torch.save({\n",
        "            'G_AB': G_AB.state_dict(),\n",
        "            'G_BA': G_BA.state_dict(),\n",
        "            'D_A': D_A.state_dict(),\n",
        "            'D_B': D_B.state_dict(),\n",
        "            'optimizer_G': optimizer_G.state_dict(),\n",
        "            'optimizer_D_A': optimizer_D_A.state_dict(),\n",
        "            'optimizer_D_B': optimizer_D_B.state_dict(),\n",
        "        }, os.path.join(checkpoints_dir, f\"cyclegan_epoch{epoch:03d}.pth\"))\n",
        "        print(f\"[Epoch {epoch}] Saved samples and checkpoint.\")\n",
        "\n",
        "\n",
        "    print(f\"Epoch {epoch} summary: cycle_loss {recon_cycle_loss/len(loaderA):.6f}, gan_loss {gan_loss_val/len(loaderA):.6f}, id_loss {id_loss_val/len(loaderA):.6f}\")\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "print(\"Training finished in {:.1f} s\".format(elapsed))\n",
        "\n",
        "\n",
        "# Save final trained models\n",
        "torch.save({\n",
        "    'G_AB': G_AB.state_dict(),\n",
        "    'G_BA': G_BA.state_dict(),\n",
        "    'D_A': D_A.state_dict(),\n",
        "    'D_B': D_B.state_dict(),\n",
        "    'optimizer_G': optimizer_G.state_dict(),\n",
        "    'optimizer_D_A': optimizer_D_A.state_dict(),\n",
        "    'optimizer_D_B': optimizer_D_B.state_dict(),\n",
        "    'epochs': epochs,\n",
        "}, os.path.join(checkpoints_dir, \"cyclegan_final.pth\"))\n",
        "\n",
        "print(\"Final model saved to:\", os.path.join(checkpoints_dir, \"cyclegan_final_T1.pth\"))\n",
        "\n",
        "\n",
        "# Harmonize Guys Images\n",
        "print(\"Generating harmonized outputs for Site A ...\")\n",
        "G_AB.eval()\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "with torch.no_grad():\n",
        "    for i in range(len(dsA)):\n",
        "        x, p = dsA[i]\n",
        "        x_t = x.unsqueeze(0).to(device) * 2.0 - 1.0\n",
        "        y = G_AB(x_t)              # in [-1,1]\n",
        "        y = (y.cpu().squeeze(0).squeeze(0).numpy() * 0.5 + 0.5)  # to [0,1]\n",
        "        y = (np.clip(y, 0.0, 1.0) * 255.0).astype(np.uint8)\n",
        "        fname = os.path.basename(p)\n",
        "        Image.fromarray(y).save(os.path.join(out_dir, fname))\n",
        "print(\"Harmonized images saved to:\", out_dir)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBcoAHuSjyg8",
        "outputId": "4995314d-8037-4ae3-e8eb-f028221fde0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num A: 88 Num B: 88 Device: cuda\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[1/100] step 0 lossG 87.2736: 100%|██████████| 22/22 [00:33<00:00,  1.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] Saved samples and checkpoint.\n",
            "Epoch 1 summary: cycle_loss 4.202847, gan_loss 2.825985, id_loss 19.107940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[2/100] step 0 lossG 16.4798: 100%|██████████| 22/22 [00:32<00:00,  1.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 summary: cycle_loss 1.928274, gan_loss 0.751455, id_loss 8.750340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[3/100] step 0 lossG 11.4327: 100%|██████████| 22/22 [00:33<00:00,  1.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 summary: cycle_loss 1.759699, gan_loss 1.017181, id_loss 7.949953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[4/100] step 0 lossG 10.0845: 100%|██████████| 22/22 [00:33<00:00,  1.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 summary: cycle_loss 1.619126, gan_loss 0.693662, id_loss 7.514774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[5/100] step 0 lossG 11.0838: 100%|██████████| 22/22 [00:34<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 summary: cycle_loss 1.509005, gan_loss 0.927016, id_loss 6.781425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[6/100] step 0 lossG 7.8949: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 summary: cycle_loss 1.550944, gan_loss 0.760387, id_loss 6.892393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[7/100] step 0 lossG 11.6001: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 summary: cycle_loss 1.507780, gan_loss 0.786389, id_loss 6.720846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[8/100] step 0 lossG 8.9516: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 summary: cycle_loss 1.413950, gan_loss 0.857402, id_loss 6.466931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[9/100] step 0 lossG 7.2751: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 summary: cycle_loss 1.383069, gan_loss 0.792991, id_loss 6.174400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[10/100] step 0 lossG 7.8480: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 10] Saved samples and checkpoint.\n",
            "Epoch 10 summary: cycle_loss 1.404026, gan_loss 0.843311, id_loss 6.128128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[11/100] step 0 lossG 9.9928: 100%|██████████| 22/22 [00:34<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 summary: cycle_loss 1.338584, gan_loss 0.827263, id_loss 5.914048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[12/100] step 0 lossG 10.1419: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 summary: cycle_loss 1.335738, gan_loss 0.783875, id_loss 5.851620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[13/100] step 0 lossG 5.7371: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 summary: cycle_loss 1.284722, gan_loss 0.834089, id_loss 5.829453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[14/100] step 0 lossG 7.1199: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 summary: cycle_loss 1.374331, gan_loss 0.792417, id_loss 5.962432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[15/100] step 0 lossG 7.1146: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 summary: cycle_loss 1.293673, gan_loss 0.934128, id_loss 5.656651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[16/100] step 0 lossG 7.9931: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 summary: cycle_loss 1.311935, gan_loss 0.756892, id_loss 5.696954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[17/100] step 0 lossG 6.7172: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 summary: cycle_loss 1.322274, gan_loss 0.857322, id_loss 5.740569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[18/100] step 0 lossG 6.6475: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 summary: cycle_loss 1.302765, gan_loss 0.825670, id_loss 5.621970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[19/100] step 0 lossG 5.3884: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 summary: cycle_loss 1.282458, gan_loss 0.884921, id_loss 5.420267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[20/100] step 0 lossG 7.7088: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 20] Saved samples and checkpoint.\n",
            "Epoch 20 summary: cycle_loss 1.200601, gan_loss 0.780595, id_loss 5.057640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[21/100] step 0 lossG 6.8912: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 summary: cycle_loss 1.225186, gan_loss 0.851986, id_loss 5.155445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[22/100] step 0 lossG 7.0830: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 summary: cycle_loss 1.243162, gan_loss 0.780902, id_loss 5.033356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[23/100] step 0 lossG 8.0133: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 summary: cycle_loss 1.267725, gan_loss 0.777713, id_loss 5.085794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[24/100] step 0 lossG 5.5435: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 summary: cycle_loss 1.210551, gan_loss 0.730660, id_loss 4.765402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[25/100] step 0 lossG 7.8013: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 summary: cycle_loss 1.239999, gan_loss 0.791207, id_loss 4.915994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[26/100] step 0 lossG 7.5373: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 summary: cycle_loss 1.217574, gan_loss 0.769793, id_loss 4.856797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[27/100] step 0 lossG 5.2766: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 summary: cycle_loss 1.184240, gan_loss 0.824978, id_loss 4.598067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[28/100] step 0 lossG 5.9271: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 summary: cycle_loss 1.297286, gan_loss 0.721386, id_loss 4.932904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[29/100] step 0 lossG 8.0621: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 summary: cycle_loss 1.239036, gan_loss 0.804899, id_loss 4.814954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[30/100] step 0 lossG 6.7068: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 30] Saved samples and checkpoint.\n",
            "Epoch 30 summary: cycle_loss 1.078550, gan_loss 0.819643, id_loss 4.168420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[31/100] step 0 lossG 5.0276: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31 summary: cycle_loss 1.084697, gan_loss 0.793865, id_loss 4.180962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[32/100] step 0 lossG 5.3060: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32 summary: cycle_loss 1.089846, gan_loss 0.806062, id_loss 4.201719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[33/100] step 0 lossG 6.6752: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33 summary: cycle_loss 1.017176, gan_loss 0.762242, id_loss 3.921550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[34/100] step 0 lossG 5.8950: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34 summary: cycle_loss 1.070679, gan_loss 0.827311, id_loss 4.172593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[35/100] step 0 lossG 6.2866: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 summary: cycle_loss 1.055493, gan_loss 0.807719, id_loss 4.050406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[36/100] step 0 lossG 6.0193: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36 summary: cycle_loss 1.080313, gan_loss 0.859964, id_loss 4.125107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[37/100] step 0 lossG 5.9675: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37 summary: cycle_loss 0.978995, gan_loss 0.781737, id_loss 3.716940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[38/100] step 0 lossG 4.8670: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38 summary: cycle_loss 0.975760, gan_loss 0.820551, id_loss 3.603480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[39/100] step 0 lossG 6.2614: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39 summary: cycle_loss 1.015913, gan_loss 0.826861, id_loss 4.069807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[40/100] step 0 lossG 7.0367: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 40] Saved samples and checkpoint.\n",
            "Epoch 40 summary: cycle_loss 0.990369, gan_loss 0.871914, id_loss 3.552930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[41/100] step 0 lossG 4.6364: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41 summary: cycle_loss 0.935925, gan_loss 0.767131, id_loss 3.583731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[42/100] step 0 lossG 4.0948: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42 summary: cycle_loss 0.942716, gan_loss 0.830753, id_loss 3.487780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[43/100] step 0 lossG 5.0671: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43 summary: cycle_loss 0.961634, gan_loss 0.778867, id_loss 3.565275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[44/100] step 0 lossG 4.2637: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44 summary: cycle_loss 1.051592, gan_loss 0.868224, id_loss 3.848730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[45/100] step 0 lossG 5.4300: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45 summary: cycle_loss 0.988690, gan_loss 0.793129, id_loss 3.543686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[46/100] step 0 lossG 5.9002: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46 summary: cycle_loss 0.917694, gan_loss 0.841910, id_loss 3.547458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[47/100] step 0 lossG 4.8844: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47 summary: cycle_loss 1.021648, gan_loss 0.779572, id_loss 3.603237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[48/100] step 0 lossG 5.1780: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48 summary: cycle_loss 0.958411, gan_loss 0.829277, id_loss 3.453103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[49/100] step 0 lossG 5.1904: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49 summary: cycle_loss 0.987068, gan_loss 0.835181, id_loss 3.421583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[50/100] step 0 lossG 4.7000: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 50] Saved samples and checkpoint.\n",
            "Epoch 50 summary: cycle_loss 0.883769, gan_loss 0.810596, id_loss 3.140362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[51/100] step 0 lossG 5.6492: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51 summary: cycle_loss 0.974660, gan_loss 0.784057, id_loss 3.339786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[52/100] step 0 lossG 5.2036: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52 summary: cycle_loss 0.916376, gan_loss 0.839932, id_loss 3.242924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[53/100] step 0 lossG 5.0744: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53 summary: cycle_loss 0.915240, gan_loss 0.762459, id_loss 3.079197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[54/100] step 0 lossG 6.3834: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54 summary: cycle_loss 0.906641, gan_loss 0.752627, id_loss 3.022783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[55/100] step 0 lossG 3.6939: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55 summary: cycle_loss 0.962648, gan_loss 0.752199, id_loss 3.274814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[56/100] step 0 lossG 5.6355: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56 summary: cycle_loss 0.898349, gan_loss 0.768035, id_loss 3.077047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[57/100] step 0 lossG 4.8496: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57 summary: cycle_loss 0.859556, gan_loss 0.755088, id_loss 2.833469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[58/100] step 0 lossG 3.6990: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58 summary: cycle_loss 0.865409, gan_loss 0.772304, id_loss 2.979260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[59/100] step 0 lossG 4.4830: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59 summary: cycle_loss 0.900977, gan_loss 0.765257, id_loss 2.918747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[60/100] step 0 lossG 3.6405: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 60] Saved samples and checkpoint.\n",
            "Epoch 60 summary: cycle_loss 0.845384, gan_loss 0.790480, id_loss 2.682338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[61/100] step 0 lossG 3.1500: 100%|██████████| 22/22 [00:34<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61 summary: cycle_loss 0.775143, gan_loss 0.770127, id_loss 2.555267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[62/100] step 0 lossG 3.8297: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62 summary: cycle_loss 0.798228, gan_loss 0.766914, id_loss 2.570464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[63/100] step 0 lossG 4.8264: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63 summary: cycle_loss 0.832727, gan_loss 0.762205, id_loss 2.630983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[64/100] step 0 lossG 4.2676: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64 summary: cycle_loss 0.785881, gan_loss 0.750742, id_loss 2.516970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[65/100] step 0 lossG 4.5467: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65 summary: cycle_loss 0.753280, gan_loss 0.768065, id_loss 2.444174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[66/100] step 0 lossG 3.5328: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66 summary: cycle_loss 0.783917, gan_loss 0.752966, id_loss 2.527139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[67/100] step 0 lossG 3.9886: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67 summary: cycle_loss 0.742051, gan_loss 0.821190, id_loss 2.495857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[68/100] step 0 lossG 3.2761: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68 summary: cycle_loss 0.775696, gan_loss 0.812280, id_loss 2.408870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[69/100] step 0 lossG 3.7644: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69 summary: cycle_loss 0.754675, gan_loss 0.706970, id_loss 2.221721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[70/100] step 0 lossG 3.6123: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 70] Saved samples and checkpoint.\n",
            "Epoch 70 summary: cycle_loss 0.747408, gan_loss 0.722197, id_loss 2.146901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[71/100] step 0 lossG 3.2396: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71 summary: cycle_loss 0.742655, gan_loss 0.743119, id_loss 2.238105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[72/100] step 0 lossG 3.5195: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72 summary: cycle_loss 0.720780, gan_loss 0.746659, id_loss 2.230993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[73/100] step 0 lossG 3.2311: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73 summary: cycle_loss 0.699817, gan_loss 0.735619, id_loss 2.072042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[74/100] step 0 lossG 2.8560: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74 summary: cycle_loss 0.675459, gan_loss 0.756321, id_loss 2.000309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[75/100] step 0 lossG 4.0533: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75 summary: cycle_loss 0.706391, gan_loss 0.774014, id_loss 2.067438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[76/100] step 0 lossG 2.9922: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76 summary: cycle_loss 0.621813, gan_loss 0.764423, id_loss 1.852366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[77/100] step 0 lossG 3.2369: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77 summary: cycle_loss 0.635202, gan_loss 0.750179, id_loss 1.880126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[78/100] step 0 lossG 3.3788: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78 summary: cycle_loss 0.668730, gan_loss 0.732958, id_loss 1.851418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[79/100] step 0 lossG 3.2036: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79 summary: cycle_loss 0.661308, gan_loss 0.695683, id_loss 1.833683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[80/100] step 0 lossG 3.6351: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 80] Saved samples and checkpoint.\n",
            "Epoch 80 summary: cycle_loss 0.637118, gan_loss 0.725885, id_loss 1.836598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[81/100] step 0 lossG 2.7839: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81 summary: cycle_loss 0.611646, gan_loss 0.737932, id_loss 1.748101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[82/100] step 0 lossG 3.6547: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82 summary: cycle_loss 0.585456, gan_loss 0.745965, id_loss 1.693215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[83/100] step 0 lossG 2.7651: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83 summary: cycle_loss 0.585173, gan_loss 0.775283, id_loss 1.696096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[84/100] step 0 lossG 2.7620: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84 summary: cycle_loss 0.598999, gan_loss 0.729980, id_loss 1.623425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[85/100] step 0 lossG 2.7286: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85 summary: cycle_loss 0.615137, gan_loss 0.705099, id_loss 1.663152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[86/100] step 0 lossG 3.1055: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86 summary: cycle_loss 0.600165, gan_loss 0.723957, id_loss 1.634889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[87/100] step 0 lossG 3.0793: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87 summary: cycle_loss 0.584373, gan_loss 0.724442, id_loss 1.570696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[88/100] step 0 lossG 2.8010: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 88 summary: cycle_loss 0.540514, gan_loss 0.739815, id_loss 1.535552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[89/100] step 0 lossG 2.6694: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89 summary: cycle_loss 0.524252, gan_loss 0.759050, id_loss 1.512426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[90/100] step 0 lossG 2.5393: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 90] Saved samples and checkpoint.\n",
            "Epoch 90 summary: cycle_loss 0.542745, gan_loss 0.750223, id_loss 1.509435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[91/100] step 0 lossG 2.7613: 100%|██████████| 22/22 [00:34<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91 summary: cycle_loss 0.563917, gan_loss 0.709010, id_loss 1.463494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[92/100] step 0 lossG 2.6409: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92 summary: cycle_loss 0.545153, gan_loss 0.711846, id_loss 1.434384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[93/100] step 0 lossG 2.6626: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93 summary: cycle_loss 0.538177, gan_loss 0.708208, id_loss 1.420702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[94/100] step 0 lossG 2.6183: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94 summary: cycle_loss 0.530389, gan_loss 0.724292, id_loss 1.405231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[95/100] step 0 lossG 2.5506: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95 summary: cycle_loss 0.525093, gan_loss 0.721647, id_loss 1.385890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[96/100] step 0 lossG 2.6263: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96 summary: cycle_loss 0.521083, gan_loss 0.721891, id_loss 1.381114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[97/100] step 0 lossG 2.3418: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97 summary: cycle_loss 0.518668, gan_loss 0.720217, id_loss 1.374062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[98/100] step 0 lossG 2.3733: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98 summary: cycle_loss 0.516000, gan_loss 0.713071, id_loss 1.365697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[99/100] step 0 lossG 2.4914: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99 summary: cycle_loss 0.513348, gan_loss 0.725563, id_loss 1.360714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch[100/100] step 0 lossG 2.7165: 100%|██████████| 22/22 [00:34<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 100] Saved samples and checkpoint.\n",
            "Epoch 100 summary: cycle_loss 0.512170, gan_loss 0.717823, id_loss 1.357627\n",
            "Training finished in 3446.1 s\n",
            "Final model saved to: checkpoints/cyclegan/cyclegan_final_T1.pth\n",
            "Generating harmonized outputs for Site A ...\n",
            "Harmonized images saved to: /content/drive/MyDrive/finalT1T2Data/outputs/harmonized_Guys_train_T1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ulbR4s1FlIR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vThPQxjMlIOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/checkpoints/cyclegan/cyclegan_final_T2.pth /content/drive/MyDrive/finalT1T2Data/samples/harmonizedData/cyclegan_final_T2.pth"
      ],
      "metadata": {
        "id": "zqkHOtKF-Wuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/checkpoints/cyclegan/cyclegan_final_T1.pth /content/drive/MyDrive/finalT1T2Data/samples/harmonizedData/cyclegan_final_T1.pth"
      ],
      "metadata": {
        "id": "sSeXrcRiFATY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate T2 harmonized images for the testing data"
      ],
      "metadata": {
        "id": "fRRVSx9B801e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generator definition\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(dim, dim, kernel_size=3),\n",
        "            nn.InstanceNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(dim, dim, kernel_size=3),\n",
        "            nn.InstanceNorm2d(dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.conv_block(x)\n",
        "\n",
        "class ResnetGenerator(nn.Module):\n",
        "    def __init__(self, input_nc=1, output_nc=1, ngf=64, n_blocks=6):\n",
        "        super().__init__()\n",
        "        model = [\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(input_nc, ngf, kernel_size=7),\n",
        "            nn.InstanceNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "        ]\n",
        "\n",
        "        # Downsample\n",
        "        mult = 1\n",
        "        for _ in range(2):\n",
        "            model += [\n",
        "                nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1),\n",
        "                nn.InstanceNorm2d(ngf * mult * 2),\n",
        "                nn.ReLU(True),\n",
        "            ]\n",
        "            mult *= 2\n",
        "\n",
        "        # ResNet blocks\n",
        "        for _ in range(n_blocks):\n",
        "            model += [ResnetBlock(ngf * mult)]\n",
        "\n",
        "        # Upsample\n",
        "        for _ in range(2):\n",
        "            model += [\n",
        "                nn.ConvTranspose2d(ngf * mult, ngf * mult // 2,\n",
        "                                   kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "                nn.InstanceNorm2d(ngf * mult // 2),\n",
        "                nn.ReLU(True),\n",
        "            ]\n",
        "            mult //= 2\n",
        "\n",
        "        model += [\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(ngf, output_nc, kernel_size=7),\n",
        "            nn.Tanh(),\n",
        "        ]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/finalT1T2Data/samples/harmonizedData/cyclegan_final_T2.pth\"\n",
        "\n",
        "G_AB = ResnetGenerator().to(device)\n",
        "ckpt = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "G_AB.load_state_dict(ckpt[\"G_AB\"])\n",
        "G_AB.eval()\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "input_dir = \"/content/drive/MyDrive/finalT1T2Data/T2_test_by_loc/Guys\"\n",
        "output_dir = \"/content/drive/MyDrive/finalT1T2Data/harmonizedTest/T2\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for p in glob(os.path.join(input_dir, \"*.png\")):\n",
        "        img = Image.open(p)\n",
        "        x = transform(img).unsqueeze(0).to(device)   # [0,1]\n",
        "        x = x * 2.0 - 1.0                             # → [-1,1]\n",
        "\n",
        "        y = G_AB(x)                                   # → [-1,1]\n",
        "        y = (y.squeeze().cpu().numpy() * 0.5 + 0.5)   # → [0,1]\n",
        "        y = np.clip(y, 0, 1)\n",
        "\n",
        "        y = (y * 255).astype(np.uint8)\n",
        "        Image.fromarray(y).save(os.path.join(output_dir, os.path.basename(p)))\n"
      ],
      "metadata": {
        "id": "p0LEcYbFlILW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E-lQYQ9p-Wqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate T1 harmonized images for the testing data"
      ],
      "metadata": {
        "id": "uERXBfLRF0ei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Generator definition\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(dim, dim, kernel_size=3),\n",
        "            nn.InstanceNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(dim, dim, kernel_size=3),\n",
        "            nn.InstanceNorm2d(dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.conv_block(x)\n",
        "\n",
        "class ResnetGenerator(nn.Module):\n",
        "    def __init__(self, input_nc=1, output_nc=1, ngf=64, n_blocks=6):\n",
        "        super().__init__()\n",
        "        model = [\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(input_nc, ngf, kernel_size=7),\n",
        "            nn.InstanceNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "        ]\n",
        "\n",
        "        # Downsample\n",
        "        mult = 1\n",
        "        for _ in range(2):\n",
        "            model += [\n",
        "                nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1),\n",
        "                nn.InstanceNorm2d(ngf * mult * 2),\n",
        "                nn.ReLU(True),\n",
        "            ]\n",
        "            mult *= 2\n",
        "\n",
        "        # ResNet blocks\n",
        "        for _ in range(n_blocks):\n",
        "            model += [ResnetBlock(ngf * mult)]\n",
        "\n",
        "        # Upsample\n",
        "        for _ in range(2):\n",
        "            model += [\n",
        "                nn.ConvTranspose2d(ngf * mult, ngf * mult // 2,\n",
        "                                   kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "                nn.InstanceNorm2d(ngf * mult // 2),\n",
        "                nn.ReLU(True),\n",
        "            ]\n",
        "            mult //= 2\n",
        "\n",
        "        model += [\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(ngf, output_nc, kernel_size=7),\n",
        "            nn.Tanh(),\n",
        "        ]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/finalT1T2Data/samples/harmonizedData/cyclegan_final_T1.pth\"\n",
        "\n",
        "G_AB = ResnetGenerator().to(device)\n",
        "ckpt = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "G_AB.load_state_dict(ckpt[\"G_AB\"])\n",
        "G_AB.eval()\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "input_dir = \"/content/drive/MyDrive/finalT1T2Data/T1_test_by_loc/Guys\"\n",
        "output_dir = \"/content/drive/MyDrive/finalT1T2Data/harmonizedTest/T1\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for p in glob(os.path.join(input_dir, \"*.png\")):\n",
        "        img = Image.open(p)\n",
        "        x = transform(img).unsqueeze(0).to(device)   # [0,1]\n",
        "        x = x * 2.0 - 1.0                             # → [-1,1]\n",
        "\n",
        "        y = G_AB(x)                                   # → [-1,1]\n",
        "        y = (y.squeeze().cpu().numpy() * 0.5 + 0.5)   # → [0,1]\n",
        "        y = np.clip(y, 0, 1)\n",
        "\n",
        "        y = (y * 255).astype(np.uint8)\n",
        "        Image.fromarray(y).save(os.path.join(output_dir, os.path.basename(p)))\n"
      ],
      "metadata": {
        "id": "ytGNSDQxlIH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tguo5oc0lIEn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}